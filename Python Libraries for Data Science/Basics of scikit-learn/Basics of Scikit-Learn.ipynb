{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a53374",
   "metadata": {},
   "source": [
    "# Scikit-Learn\n",
    "\n",
    "- It provides simple and efficient tools for pre-processing and predictive modeling\n",
    "\n",
    "**Pre-processing**\n",
    "- Imputes Missing Values\n",
    "- Encode Categorical Variables\n",
    "- Scaling/Normalizing of Data\n",
    "\n",
    "**Model building**\n",
    "- Identifying category to which an object belongs.\n",
    "- Predicting a cotinuous-valued attribute associated with an object.\n",
    "\n",
    "**Automating the process**\n",
    "- After the model building create pipelines to automate the pre-processing part and predict the target using the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8720c66",
   "metadata": {},
   "source": [
    "**Steps to build a model in scikit-learn.**\n",
    "\n",
    "1. Import hte model \n",
    "2. Prepare the data set\n",
    "3. Separate the independent and the target values\n",
    "4. Create an object of the model\n",
    "5. Fill the model with the data\n",
    "6. Use the model to predict the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6666ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the scikit-learn library \n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478688a9",
   "metadata": {},
   "source": [
    "**If you got an error while running the above cell, import it by using the following command.**\n",
    "\n",
    "If you are using anaconda with python3: **!pip install scikit-learn**\n",
    "\n",
    "If you are using jupyter with python3: **!pip3 install scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc34b30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the version \n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478e609",
   "metadata": {},
   "source": [
    "**We have seen int the pandas notebook that we have some missing values in out data.**\n",
    "**We will impute those missing values using the scikit-learn imputer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dbdead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  1463\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  2410\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data set and check for the null values\n",
    "import pandas as pd\n",
    "data = pd.read_csv('big_mart_sales.csv')\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afea89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the simple imputer \n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24bbdb0",
   "metadata": {},
   "source": [
    "- For imputing the missing values, we will use **Simpleimputer**.\n",
    "- First we will create an object of the imputer and define the strategy.\n",
    "- We will impute the Item_Weight by mean value and Outlet_Size by most frequent value.\n",
    "- Fit the object with the data.\n",
    "- Transform the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d4c199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the object of the imputer for Item_Weight and Outlet_Size\n",
    "impute_weight = SimpleImputer(strategy='mean')\n",
    "impute_size = SimpleImputer(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75da47cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the Item_Weight impute with the data and transform \n",
    "impute_weight.fit(data[['Item_Weight']])\n",
    "data.Item_Weight = impute_weight.transform(data[['Item_Weight']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be35a81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the Outlet_Size impute with the data and transform \n",
    "impute_size.fit(data[['Outlet_Size']])\n",
    "data.Outlet_Size = impute_size.transform(data[['Outlet_Size']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdf1b713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier              0\n",
       "Item_Weight                  0\n",
       "Item_Fat_Content             0\n",
       "Item_Visibility              0\n",
       "Item_Type                    0\n",
       "Item_MRP                     0\n",
       "Outlet_Identifier            0\n",
       "Outlet_Establishment_Year    0\n",
       "Outlet_Size                  0\n",
       "Outlet_Location_Type         0\n",
       "Outlet_Type                  0\n",
       "Item_Outlet_Sales            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the null values\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a9ffe",
   "metadata": {},
   "source": [
    "- Now, after the processing step, we separate the independent and target variable and pass the data to the model object to train the model.\n",
    "\n",
    "- if we have a problem in which we have to identify the category of an object based on some features. For example whether the given picture is of a cat or a dog. Thease are classsification problems. \n",
    "\n",
    "- Or, if we have to indentify a continuous attribute like predicting sales based on some features. these are **Regression Problems**.\n",
    "\n",
    "**SCIKIT-LEARN** has tools which will help you build Regression, Classification models and many others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "766e8c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the very basic models scikit learn has.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fb590a",
   "metadata": {},
   "source": [
    "After we have build the model now wherever new data points are added to the existing data, we need to perform the same preprocessing steps again before we can use the model to make predictions. This becomes a tedious and time consuming process!\n",
    "\n",
    "So, scikit-learn provides tools to create a pipeline of all those steps that will make your work a lot more easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9426b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
